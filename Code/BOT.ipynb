{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp3dlz_Pf_wE"
      },
      "outputs": [],
      "source": [
        "# For handling data\n",
        "import os\n",
        "\n",
        "# For text preprocessing\n",
        "import re\n",
        "\n",
        "# For NLP tasks\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Download NLTK data (only needed once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Optional: for vectorization and building the model\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression  # or any ML model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the two large text files (Only use this if you have two txt files)\n",
        "with open(\"file_name.txt\", \"r\", encoding=\"utf-8\") as file1:\n",
        "    text1 = file1.read()\n",
        "\n",
        "with open(\"file_name2.txt\", \"r\", encoding=\"utf-8\") as file2:\n",
        "    text2 = file2.read()\n",
        "\n",
        "# Combine the content if needed\n",
        "full_text = text1 + \"\\n\" + text2\n",
        "\n",
        "# Print basic info\n",
        "print(\"Length of combined text:\", len(full_text))\n",
        "print(\"First 500 characters:\\n\", full_text[:500])"
      ],
      "metadata": {
        "id": "iwJZ9NJPgMKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Extract Q&A pairs using regex\n",
        "qa_pairs = re.findall(r\"Q[:：](.*?)A[:：](.*?)(?=Q[:：]|$)\", full_text, re.DOTALL)\n",
        "\n",
        "# Clean whitespace\n",
        "qa_pairs = [(q.strip(), a.strip()) for q, a in qa_pairs if q.strip() and a.strip()]\n",
        "\n",
        "# Preview\n",
        "print(f\"Extracted {len(qa_pairs)} Q&A pairs.\")\n",
        "for i in range(min(3, len(qa_pairs))):\n",
        "    print(f\"\\nQ: {qa_pairs[i][0]}\\nA: {qa_pairs[i][1]}\")"
      ],
      "metadata": {
        "id": "LxrTjyNzhLRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Split the pairs into questions and answers\n",
        "questions, answers = zip(*qa_pairs)\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(questions)\n",
        "\n",
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "\n",
        "# Split the pairs into questions and answers\n",
        "questions, answers = zip(*qa_pairs)\n",
        "\n",
        "#(Use this if you're using linear regression to build the chatbot)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train the classifier on question-answer pairs\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X, answers)"
      ],
      "metadata": {
        "id": "-EkVxkJAge1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean speaker labels like \"Parent:\", \"Doctor:\"\n",
        "def clean_answer(text):\n",
        "    return re.sub(r'\\b(Parent|Doctor|Patient):\\s*', '', text).strip()\n",
        "\n",
        "# Function to get the best matching answer\n",
        "def get_best_answer(user_input, top_k=1, threshold=0.3):\n",
        "    user_vec = vectorizer.transform([user_input])\n",
        "    similarities = cosine_similarity(user_vec, X).flatten()\n",
        "\n",
        "    top_indices = similarities.argsort()[::-1][:top_k]\n",
        "    top_scores = similarities[top_indices]\n",
        "    results = []\n",
        "\n",
        "    for i, score in zip(top_indices, top_scores):\n",
        "        if score >= threshold:\n",
        "            return clean_answer(answers[i])\n",
        "\n",
        "    #for i, score in zip(top_indices, top_scores):\n",
        "     #   if score >= threshold:\n",
        "      #      results.append((questions[i], answers[i]))\n",
        "\n",
        "    if not results:\n",
        "        return \"I'm not sure about that. Could you please rephrase or ask a different question?\"\n",
        "\n",
        "    return clean_answer(results[0][1])\n",
        "\n",
        "# Gradio interface function\n",
        "def chatbot_interface(user_input):\n",
        "    return get_best_answer(user_input)\n",
        "\n",
        "# Launch Gradio app\n",
        "gr.Interface(\n",
        "    fn=chatbot_interface,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Ask any question about...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Chatbot Name\",\n",
        "    description=\"Ask questions from your knowledge base.\",\n",
        "    theme=\"default\",\n",
        ").launch(share=True)"
      ],
      "metadata": {
        "id": "Z1C3IOMRg0xs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}